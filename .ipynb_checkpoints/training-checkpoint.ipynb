{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af91b78-b2bb-4c16-b853-4dcaa6f28b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166ed184-879b-4fe4-95cc-ae08ed1e3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9c3e8e-cf01-4757-8b6b-cb937c585169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f64378-7893-47cc-a145-c27276cc21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCDFDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = [f for f in os.listdir(root_dir) if f.endswith('.nc')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.root_dir, self.file_list[idx])\n",
    "        \n",
    "        # Load NetCDF data\n",
    "        dataset = nc.Dataset(file_path)\n",
    "        data = dataset.variables['t2m'][:].astype(np.float32)  # Adjust 'data' to the variable name in your file\n",
    "        dataset.close()\n",
    "        \n",
    "        # Reshape the data to (1, 50, 721, 1440)\n",
    "        data = data.reshape(1, 50, 721, 1440)\n",
    "        return torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a95c441-e33a-4770-8411-c5026f78c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data directories\n",
    "gfs_biased_dir = 'GFS/'\n",
    "era5_unbiased_dir = 'ERA5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fa4d71-2715-42e6-a2d5-ddaf76acaf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for GFS (biased) and ERA5 (unbiased) data\n",
    "gfs_dataset = NetCDFDataset(root_dir=gfs_biased_dir)\n",
    "era5_dataset = NetCDFDataset(root_dir=era5_unbiased_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0cf0900-8b01-4bc0-9a3e-0c141b84780e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10a01c030>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1  # Adjust batch size as needed\n",
    "shuffle = False\n",
    "num_workers = 0  # Adjust the number of workers for data loading\n",
    "seed = 42  # Your desired seed value\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecdd73b5-63ae-44f1-9870-a38fad9637ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_data_loader = DataLoader(gfs_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "era5_data_loader = DataLoader(era5_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e184b2-8529-4c27-9729-6c96f1ba2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.ReLU(True),\n",
    "            #nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        )\n",
    "        \n",
    "        # Bottleneck (no further reduction of dimensions)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Create your autoencoder model\n",
    "autoencoder = Autoencoder().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9f81b-de34-4be7-9261-ec48b8974f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    autoencoder = nn.DataParallel(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71b8e8f-f552-4b18-8049-1ee25f1f76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae2ab8-fad3-4b8d-ad49-24ac75a2a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with tqdm\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Wrap the DataLoader with tqdm for a progress bar\n",
    "    for gfs_data, era5_data in tqdm(zip(gfs_data_loader, era5_data_loader), desc=f'Epoch [{epoch+1}/{num_epochs}]'):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(gfs_data.to(device))\n",
    "        loss = criterion(outputs, era5_data.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Calculate and print the average loss for the epoch\n",
    "    avg_loss = total_loss / len(gfs_data_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(autoencoder.module.state_dict() if isinstance(autoencoder, nn.DataParallel) else autoencoder.state_dict(), 'autoencoder_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794295b-7dd4-4cc7-a4d9-f558423eed18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec2d26-8d9f-499a-9fbf-cc5a057d3f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e05f0-0b74-4d34-93fa-37907eff4f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2443754-4c70-49a0-b1d3-e629d1a531a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5652ab8-8ad9-47df-9f62-a5eb93da0c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df467994-472c-4781-8e64-02496c79e286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1b8cb-bb74-4f1d-a300-378373d4b7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb31ec-4c72-45b6-b53c-9ab1151b0dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47b2ab-a3fd-4472-b01d-a2d06f62d412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a12db-74c4-4c15-8573-0782bb9822f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5a23e-c670-422a-981a-152599495230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0ff6b9-c56b-436a-b62e-cb639823cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = nn.Conv3d(1, 64, kernel_size=(3,3,3), padding=(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd18773-8483-4e67-b3fd-5f77acc68195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 50, 721, 1440])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9320ed3-0c7a-4700-93ca-efb797db311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = first(gfs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37058878-ede6-4346-b146-b81d7c5bdca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 50, 721, 1440])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db914ebc-b07b-4a98-9e49-709198b80bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "second = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c662b4bf-40af-4a11-ba5f-3156497dc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = second(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46a757a3-f10e-43b4-a25c-8a1040b27359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 50, 721, 1440])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c2d98c1-9d87-45da-b357-253f429536dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "third = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a5017a5-7686-4636-b16c-6c39259bc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = third(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c47cc9a-4a92-42a7-9c76-a0d2ce7452ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 25, 360, 720])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1fbc4bb-e7e6-4968-854a-7627413f9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth = nn.ConvTranspose3d(64, 1, kernel_size=(3,3,3), padding=(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e917431d-c12b-47cc-907f-6aa39e945cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = fourth(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ab57395-f586-48bc-aedc-efa5cd6329a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 50, 721, 1440])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e786304-e696-41d4-8381-323931fa52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv3d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            #nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))gfs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ffa4046-c6e8-41e5-88a8-345173d7e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = autoencoder(gfs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "577ddc2e-5717-47f4-ae3c-317d78c891d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 50, 721, 1440])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b5d3ac-cf6a-4972-9f31-917d14a4875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=50, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)),\n",
    "            nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        )\n",
    "        \n",
    "        # Bottleneck (will be completed soon)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.LSTM(input_size=256, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True),\n",
    "            nn.ConvTranspose3d(in_channels=128, out_channels=50, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "autoencoder = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f4451b-f298-49ef-9241-7c549c3024cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466ff34-9739-4a28-82c7-1666e582cd7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4bc",
   "language": "python",
   "name": "ml4bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
