{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9af91b78-b2bb-4c16-b853-4dcaa6f28b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80f64378-7893-47cc-a145-c27276cc21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCDFDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = [f for f in os.listdir(root_dir) if f.endswith('.nc')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.root_dir, self.file_list[idx])\n",
    "        \n",
    "        # Load NetCDF data\n",
    "        dataset = nc.Dataset(file_path)\n",
    "        data = dataset.variables['t2m'][:].astype(np.float32)  # Adjust 'data' to the variable name in your file\n",
    "        dataset.close()\n",
    "        \n",
    "        # Reshape the data to (1, 50, 721, 1440)\n",
    "        data = data.reshape(1, 50, 721, 1440)\n",
    "        return torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a95c441-e33a-4770-8411-c5026f78c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data directories\n",
    "gfs_biased_dir = 'GFS/'\n",
    "era5_unbiased_dir = 'ERA5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0fa4d71-2715-42e6-a2d5-ddaf76acaf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for GFS (biased) and ERA5 (unbiased) data\n",
    "gfs_dataset = NetCDFDataset(root_dir=gfs_biased_dir)\n",
    "era5_dataset = NetCDFDataset(root_dir=era5_unbiased_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0cf0900-8b01-4bc0-9a3e-0c141b84780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  # Adjust batch size as needed\n",
    "shuffle = False\n",
    "num_workers = 0  # Adjust the number of workers for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecdd73b5-63ae-44f1-9870-a38fad9637ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_data_loader = DataLoader(gfs_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "era5_data_loader = DataLoader(era5_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30e184b2-8529-4c27-9729-6c96f1ba2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.ReLU(True),\n",
    "            #nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        )\n",
    "        \n",
    "        # Bottleneck (no further reduction of dimensions)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=(3,3,3), padding=(1,1,1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a71b8e8f-f552-4b18-8049-1ee25f1f76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fd2b00f-edd9-4ddb-92d8-e2b348373c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 77059.1016\n",
      "Epoch [2/10], Loss: 76529.3516\n",
      "Epoch [3/10], Loss: 76518.3125\n",
      "Epoch [4/10], Loss: 76518.3125\n",
      "Epoch [5/10], Loss: 76518.3125\n",
      "Epoch [6/10], Loss: 76518.3125\n",
      "Epoch [7/10], Loss: 76518.3125\n",
      "Epoch [8/10], Loss: 76518.3125\n",
      "Epoch [9/10], Loss: 76518.3125\n",
      "Epoch [10/10], Loss: 76518.3125\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    for gfs_data, era5_data in zip(gfs_data_loader, era5_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(gfs_data)\n",
    "        loss = criterion(outputs, era5_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda93d00-d3e2-4e9e-83e0-144ae26ea55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0a34e-d7a8-461d-99e4-f16668cbc7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03914649-77ad-467b-8613-a5aa2d7b7385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794295b-7dd4-4cc7-a4d9-f558423eed18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec2d26-8d9f-499a-9fbf-cc5a057d3f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e05f0-0b74-4d34-93fa-37907eff4f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2443754-4c70-49a0-b1d3-e629d1a531a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5652ab8-8ad9-47df-9f62-a5eb93da0c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df467994-472c-4781-8e64-02496c79e286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1b8cb-bb74-4f1d-a300-378373d4b7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb31ec-4c72-45b6-b53c-9ab1151b0dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47b2ab-a3fd-4472-b01d-a2d06f62d412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a12db-74c4-4c15-8573-0782bb9822f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5a23e-c670-422a-981a-152599495230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0ff6b9-c56b-436a-b62e-cb639823cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = nn.Conv3d(1, 64, kernel_size=(3,3,3), padding=(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd18773-8483-4e67-b3fd-5f77acc68195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 50, 721, 1440])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9320ed3-0c7a-4700-93ca-efb797db311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = first(gfs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37058878-ede6-4346-b146-b81d7c5bdca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 50, 721, 1440])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db914ebc-b07b-4a98-9e49-709198b80bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "second = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c662b4bf-40af-4a11-ba5f-3156497dc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = second(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46a757a3-f10e-43b4-a25c-8a1040b27359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 50, 721, 1440])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c2d98c1-9d87-45da-b357-253f429536dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "third = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a5017a5-7686-4636-b16c-6c39259bc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = third(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c47cc9a-4a92-42a7-9c76-a0d2ce7452ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 25, 360, 720])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1fbc4bb-e7e6-4968-854a-7627413f9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth = nn.ConvTranspose3d(64, 1, kernel_size=(3,3,3), padding=(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e917431d-c12b-47cc-907f-6aa39e945cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = fourth(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ab57395-f586-48bc-aedc-efa5cd6329a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 50, 721, 1440])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e786304-e696-41d4-8381-323931fa52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv3d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            #nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))gfs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ffa4046-c6e8-41e5-88a8-345173d7e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = autoencoder(gfs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "577ddc2e-5717-47f4-ae3c-317d78c891d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 50, 721, 1440])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b5d3ac-cf6a-4972-9f31-917d14a4875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=50, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2)),\n",
    "            nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        )\n",
    "        \n",
    "        # Bottleneck (will be completed soon)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.LSTM(input_size=256, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True),\n",
    "            nn.ConvTranspose3d(in_channels=128, out_channels=50, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "autoencoder = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f4451b-f298-49ef-9241-7c549c3024cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466ff34-9739-4a28-82c7-1666e582cd7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4bc",
   "language": "python",
   "name": "ml4bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
