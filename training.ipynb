{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af91b78-b2bb-4c16-b853-4dcaa6f28b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166ed184-879b-4fe4-95cc-ae08ed1e3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9c3e8e-cf01-4757-8b6b-cb937c585169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f64378-7893-47cc-a145-c27276cc21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.ReLU(True),\n",
    "            # nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        )\n",
    "\n",
    "        # Bottleneck (no further reduction of dimensions)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(32, 1, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Create autoencoder model and use all available GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    autoencoder = nn.DataParallel(Autoencoder()).to(device)\n",
    "else:\n",
    "    autoencoder = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2401c98b-2cab-4fff-81a9-276fd9f5a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCDFDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = [f for f in os.listdir(root_dir) if f.endswith('.nc')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.root_dir, self.file_list[idx])\n",
    "\n",
    "        # Load NetCDF data\n",
    "        dataset = nc.Dataset(file_path)\n",
    "        data = dataset.variables['t2m'][:].astype(np.float32)\n",
    "        dataset.close()\n",
    "\n",
    "        # Reshape the data to (1, 50, 721, 1440)\n",
    "        data = data.reshape(1, 50, 721, 1440)\n",
    "        return torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a95c441-e33a-4770-8411-c5026f78c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data directories\n",
    "gfs_biased_dir = 'GFS/'\n",
    "era5_unbiased_dir = 'ERA5/'\n",
    "\n",
    "batch_size = 2\n",
    "shuffle = False\n",
    "num_workers = 0\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.01)\n",
    "\n",
    "# Create data loaders for GFS (biased) and ERA5 (unbiased) data\n",
    "gfs_dataset = NetCDFDataset(root_dir=gfs_biased_dir)\n",
    "era5_dataset = NetCDFDataset(root_dir=era5_unbiased_dir)\n",
    "\n",
    "gfs_data_loader = DataLoader(gfs_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "era5_data_loader = DataLoader(era5_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa4d71-2715-42e6-a2d5-ddaf76acaf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]:  40%|███████████████▏                      | 4/10 [02:46<04:04, 40.78s/it]"
     ]
    }
   ],
   "source": [
    "# Training loop with a custom progress bar\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Create a custom progress bar for the epoch\n",
    "    progress_bar = tqdm(enumerate(zip(gfs_data_loader, era5_data_loader)), total=len(gfs_data_loader), desc=f'Epoch [{epoch+1}/{num_epochs}]', dynamic_ncols=True)\n",
    "    for batch_idx, (gfs_data, era5_data) in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(gfs_data.to(device))\n",
    "        loss = criterion(outputs, era5_data.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    progress_bar.close()  # Close the custom progress bar\n",
    "\n",
    "    # Calculate and print the average loss for the epoch\n",
    "    avg_loss = total_loss / len(gfs_data_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(autoencoder.module.state_dict() if isinstance(autoencoder, nn.DataParallel) else autoencoder.state_dict(), 'autoencoder_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4bc",
   "language": "python",
   "name": "ml4bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
